# @package _global_

# kill all idle processes using:
# > ps aux | grep ray:: | grep -v grep | awk '{print $2}' | xargs kill -9

defaults:
  - override /space: search_2.yaml
  - override /runner: default.yaml

base:
  name: search_reader
  target_metric: validation/reader/Accuracy
  target_mode: max
  # resources
  gpus: 4
  cpus: 16

ray:
  local_mode: False
  configure_logging: False

experiment:
  experiment: reader_only.yaml
  corpus: none.yaml
  sys: titan.yaml
  cache_dir: ${sys.cache_dir}
  target_metric: ${base.target_metric}
  target_mode: ${base.target_mode}
  seed: null
  print_config: False
  verbose: False
  ignore_warnings: True
  trainer.progress_bar_refresh_rate: 0
  trainer.checkpoint_callback: True
  logger.wandb.group: ${base.name}
  callbacks: tune.yaml
  callbacks.model_checkpoint.cleanup_threshold: 0.6
  datamodule.train_batch_size: 24
  datamodule.eval_batch_size: 512
  datamodule.num_workers: ${base.cpus}
  trainer.max_epochs: 100
  trainer.gpus: ${base.gpus}
  trainer.accelerator: dp


runner:
  search_alg:
    points_to_evaluate:
      - model.hidden_size: 128
        model.lr: 0.0001
        model.weight_decay: 0.001
        model.bert.pretrained_model_name_or_path: dmis-lab/biobert-base-cased-v1.1
        model.bert.hidden_dropout_prob: 0.1
        model.bert.attention_probs_dropout_prob: 0.1
        seed: 1
      - model.hidden_size: 128
        model.lr: 0.0001
        model.weight_decay: 0.001
        model.bert.pretrained_model_name_or_path: dmis-lab/biobert-base-cased-v1.2
        model.bert.hidden_dropout_prob: 0.1
        model.bert.attention_probs_dropout_prob: 0.1
        seed: 1
