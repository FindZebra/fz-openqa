defaults:
  - module: ???
  - optimizer: adamw
  - lr_scheduler: linear
  - reader: transformer
  - retriever: transformer

_target_: fz_openqa.modeling.Model

reader_id: bert-base-uncased
retriever_id: bert-base-uncased
tokenizer: ${datamodule.tokenizer}
cache_dir: ${sys.shared_cache_dir}
bert_lr: 1e-5
lr: 1e-3
weight_decay: 0.01
monitor_metric: ${base.target_metric}
num_training_steps: 10000
num_warmup_steps: 1000
