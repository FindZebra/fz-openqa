# @package _global_

defaults:
  - override /trainer: minimal
  - override /model: ???
  - override /datamodule: openqa
  - override /callbacks:
      - checkpoint
      - progress_bar
      - print_table
  - override /logger: wandb


base:
  seed: null
  target_metric: ???
  target_mode: ???
  exp_info: "--"
  batch_size: 32
  device_batch_size: 1
  eval_device_batch_size: 8
  infer_batch_mul: 100
  n_devices: ${int_max:1,${trainer.gpus}}
  step_batch_size: ${int_mul:${base.device_batch_size},${base.n_devices}}
  accumulate_grad_batches: ${int_div:${base.batch_size},${base.step_batch_size}}
  sharing_strategy: file_system
  git_hash: ${git_hash:}
  git_hash_short: ${git_hash_short:}
  ckpt_filename: "best-model-{epoch:02d}-{step}"

trainer:
  gpus: ${n_gpus:}
  strategy: dp
  accumulate_grad_batches: ${base.accumulate_grad_batches}
  max_steps: 1_000_000

model:
  lr: 1e-5
  weight_decay: 1e-3


datamodule:
  train_batch_size: 16
  valid_batch_size: 100
  max_length: 512
  subset_size: null
  num_workers: 8
  n_documents: 10
  max_pos_docs: 1
  output_columns: null

logger:
  wandb:
    group: base
