# @package _global_

defaults:
  - mc_openqa
  - override /datamodule/preprocessing_op: multi_choice_to_generative
  - override /datamodule/transform: strip_answer
  - override /model/module/reader_head: none
  - override /model/module/gradients: distillation

# todo: update ckpt path
setup_with_model: https://f001.backblazeb2.com/file/FindZebraData/fz-openqa/checkpoints/medmcqa-biolink-base-cross-dpr-1.5.zip
checkpoint_type: best

trainer:
  max_steps: 100_000
  val_check_interval: 0.5

base:
  target_metric: validation/loss
  target_mode: min
  device_batch_size: 2
  eval_device_batch_size: 4

model:
  lr_scheduler:
    num_warmup_steps: 1_000
    num_training_steps: 1_000_000 # constant learning rate
  parameters: null
  module:
    strip_answer_from_question: true


datamodule:
  dataset_update: null
  dset_name: medqa-us+medmcqa
  corpus_name: medwiki
  es_temp: 100_000
  # es_weight: 0
  n_documents: 16
  n_retrieved_documents: 300
  # n_max_retrieved_documents: 1_000
  index_builder:
    persist_cache: true

logger:
  wandb:
    group: distillation-${datamodule.dset_name}
