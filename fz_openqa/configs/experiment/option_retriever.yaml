# @package _global_

defaults:
  - colbert_qa_retriever
  - override /model: option_retriever
  - override /model/head: cls # todo colbert
  - override /model/bert: pubmed # todo: pubmed
  - override /datamodule/builder: concat_openqa

base:
  seed: null
  target_metric: validation/reader/logp
  target_mode: max

trainer:
  gpus: 8
  strategy: dp
  min_epochs: 1
  max_epochs: 1000
  accumulate_grad_batches: 4
  val_check_interval: 0.25

model:
  module:
    resample_k: 10
    alpha: 0

datamodule:
  # how often to map the dataset
  mapping_freq: null

  # dataloader
  train_batch_size: 8
  eval_batch_size: 16
  num_workers: 16 # setting this too high might lead `Dataset.map()` to hang
  persistent_workers: false
  pin_memory: true
  # drop_last: true # todo: fix this

  # dataset builder
  use_subset: false
  num_proc: 4
  output_columns:
    - answer.target
    - question.input_ids
    - question.attention_mask
    - document.input_ids
    - document.attention_mask
    - document.row_idx
    - document.match_score
    - document.retrieval_score

  # documents
  n_documents:
    train: 100
    validation: 100
    test: 100
  max_pos_docs: 1
  filter_unmatched: false
  select_mode: sample

  # tag documents as positive or negative
  relevance_classifier:
    interpretable: false

  # OpenQA builder parameters
  builder:
    batch_size: 100
    writer_batch_size: 1000
    dataset_builder:
      n_query_tokens: 0
    corpus_builder:
      use_subset: false

  # Index parameters
  index_builder:
    loader_kwargs:
      batch_size: 1000
      num_workers: 8
      pin_memory: true

  transform:
    rate: 0

logger:
  wandb:
    group: option-retriever
