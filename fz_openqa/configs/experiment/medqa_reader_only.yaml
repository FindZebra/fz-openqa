# @package _global_

defaults:
  - base
  - override /model: medqa_reader
  - override /model/bert: pubmed_multiple_choice
  - override /datamodule/builder: concat_openqa
  - override /datamodule/index_builder: elasticsearch
  - override /datamodule/relevance_classifier: none
  - override /datamodule/sampler: priority
  - override /datamodule/transform: view_reader_concat
#  - override /datamodule/dataset_filter: none
  - override /datamodule/builder/analytics: none
  - override /logger: wandb
  - override /callbacks:
      - checkpoint
      - progress_bar
      - lr_monitor

base:
  seed: 1 #${seed}
  target_metric: validation/reader/Accuracy
  target_mode: max
  exp_info: "--"
  batch_size: 32
  device_batch_size: 1
  eval_device_batch_size: 8
  infer_batch_mul: 100


trainer:
  gpus: 8
  strategy: dp
  min_epochs: 1
  max_epochs: 30
  gradient_clip_val: 2.0
  accumulate_grad_batches: 4
  val_check_interval: 1.0
  precision: 32

model:
  lr: 1e-5
  weight_decay: 1e-3
  num_warmup_steps: 1_000
  num_training_steps: 10_000

datamodule:
  use_subset: false # todo: debug: remove
  train_batch_size: 16
  eval_batch_size: 32
  num_proc: 4
  num_workers: 4
  output_columns:
    - question.input_ids
    - question.attention_mask
    - document.input_ids
    - document.attention_mask
    - document.row_idx
    - document.match_score
    - document.retrieval_score
    - document.retrieval_rank
    - answer.input_ids
    - answer.attention_mask
    - answer.target

  # documents
  n_retrieved_documents: 100
  n_documents: 3

  # document sampler
  sampler:
    total: ${datamodule.n_documents}
    largest:
      train: true
      validation: true
      test: true

  index_builder:
    es_temperature: 10. # divide the scores by a factor 10 (more uniform distribution)
    auxiliary_weight: 4. # boost the answer options by a factor (5 = 1 + 4)

  # encoding tokens
  add_encoding_tokens: true
  add_special_tokens: true

  # tag documents as positive or negative
  relevance_classifier:
    interpretable: false

  # OpenQA builder parameters
  builder:
    batch_size: 100
    writer_batch_size: 1_000
    dataset_builder:
      dset_name: medqa-us # todo: change to TW
      min_answer_length: 3
      n_query_tokens: 1
    corpus_builder:
      to_sentences: false
      use_subset: false # todo: debug: remove
      passage_length: 200
      passage_stride: 200

logger: null
callbacks: null

#logger:
#  wandb:
#    group: baseline-reader-us # name your experiment here
